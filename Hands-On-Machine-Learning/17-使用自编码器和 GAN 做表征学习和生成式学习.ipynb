{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 章节前言\n",
    "自编码器是能够在无监督（即，训练集是未标记）的情况下学习输入数据的紧密表征（叫做潜在表征或编码）的人工神经网络。这些编码通常具有比输入数据低得多的维度，使得自编码器对降维有用（参见第 8 章）。自编码器还可以作为强大的特征检测器，它们可以用于无监督的深度神经网络预训练（正如我们在第 11 章中讨论过的）。最后，一些自编码器是生成式模型：他们能够随机生成与训练数据非常相似的新数据。例如，您可以在脸图片上训练自编码器，然后可以生成新脸。但是生成出来的图片通常是模糊且不够真实。\n",
    "\n",
    "相反，用对抗生成网络（GAN）生成的人脸可以非常逼真，甚至让人认为他们是真实存在的人。你可以去这个网址，这是用 StyleGAN 生成的人脸，自己判断一下（还可以去这里，看看 GAN 生成的卧室图片），GAN 现在广泛用于超清图片涂色，图片编辑，将草图变为照片，增强数据集，生成其它类型的数据（比如文本、音频、时间序列），找出其它模型的缺点并强化，等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自编码器和 GAN 都是无监督的，都可以学习紧密表征，都可以用作生成模型，有许多相似的应用，但原理非常不同：\n",
    "\n",
    "自编码器是通过学习，将输入复制到输出。听起来很简单，但内部结构会使其相当困难。例如，你可以限制潜在表征的大小，或者可以给输入添加噪音，训练模型恢复原始输入。这些限制阻止自编码器直接将输入复制到输出，可以强迫模型学习数据的高效表征。总而言之，编码是自编码器在一些限制下学习恒等函数的副产品。\n",
    "\n",
    "GAN 包括两个神经网络：一个生成器尝试生成和训练数据相似的数据，一个判别器来区分真实数据和假数据。特别之处在于，生成器和判别器在训练过程中彼此竞争：生成器就像一个制造伪钞的罪犯，而判别器就像警察一样，要把真钱挑出来。对抗训练（训练竞争神经网络），被认为是近几年的一大进展。在 2016 年，Yann LeCun 甚至说 GAN 是过去 10 年机器学习领域最有趣的发明。\n",
    "\n",
    "本章中，我们先探究自编码器的工作原理，如何做降维、特征提取、无监督预训练将、如何用作生成式模型。然后过渡到 GAN。先用 GAN 生成假图片，可以看到训练很困难。会讨论对抗训练的主要难点，以及一些解决方法。先从自编码器开始。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有效的数据表征\n",
    "以下哪一个数字序列更容易记忆？\n",
    "\n",
    "40, 27, 25, 36, 81, 57, 10, 73, 19, 68\n",
    "50, 48, 46, 44, 42, 40, 38, 36, 34, 32, 30, 28, 26, 24, 22, 20, 18, 16, 14\n",
    "\n",
    "乍一看，第一个序列似乎应该更容易，因为它要短得多。 但是，如果仔细观察第二个序列，就会发现它是从 50 到 14 的偶数。一旦你注意到这个规律，第二个序列比第一个更容易记忆，因为你只需要记住规律就成，开始的数字和结尾的数字。请注意，如果您可以快速轻松地记住非常长的序列，则不会在意第二个序列中存在的规律。 只要记住每一个数字，就够了。 事实上，很难记住长序列，因此识别规律非常有用，并且希望能够澄清为什么在训练过程中限制自编码器会促使它发现并利用数据中的规律。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "记忆、感知和模式匹配之间的关系在 20 世纪 70 年代早期由 William Chase 和 Herbert Simon 研究。 他们观察到，专业棋手能够通过观看棋盘 5 秒钟就能记住所有棋子的位置，这是大多数人认为不可能完成的任务。 然而，只有当这些棋子被放置在现实位置（来自实际比赛）时才是这种情况，而不是随机放置棋子。 国际象棋专业棋手没有比你更好的记忆，他们只是更容易看到国际象棋的规律，这要归功于他们的比赛经验。 观察规律有助于他们有效地存储信息。\n",
    "\n",
    "就像这个记忆实验中的象棋棋手一样，一个自编码器会查看输入信息，将它们转换为高效的潜在表征，然后输出一些（希望）看起来非常接近输入的东西。 自编码器总是由两部分组成：将输入转换为潜在表征的编码器（或识别网络），然后是将潜在表征转换为输出的解码器（或生成网络）（见图 17-1）。\n",
    "\n",
    "<img src='\n",
    "https://hands1ml.apachecn.org/img/133f15a30a9de1a24f0a24873dd09824.png\n",
    "'>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如你所见，自编码器通常具有与多层感知器（MLP，请参阅第 10 章）相同的体系结构，但输出层中的神经元数量必须等于输入数量。 在这个例子中，只有一个由两个神经元（编码器）组成的隐藏层和一个由三个神经元（解码器）组成的输出层。由于自编码器试图重构输入，所以输出通常被称为重建，并且损失函数包含重建损失，当重建与输入不同时，重建损失会对模型进行惩罚。\n",
    "\n",
    "由于内部表征具有比输入数据更低的维度（它是 2D 而不是 3D），所以自编码器被认为是不完整的。 不完整的自编码器不能简单地将其输入复制到编码，但它必须找到一种方法来输出其输入的副本。 它被迫学习输入数据中最重要的特征（并删除不重要的特征）。\n",
    "\n",
    "我们来看看如何实现一个非常简单的不完整的自编码器，以降低维度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用不完整的线性自编码器来做 PCA\n",
    "如果自编码器仅使用线性激活并且损失函数是均方误差（MSE），最终其实是做了主成分分析（参见第 8 章）。\n",
    "\n",
    "以下代码创建了一个简单的线性自编码器，以在 3D 数据集上执行 PCA，并将其投影到 2D："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "encoder = keras.models.Sequential([keras.layers.Dense(2, input_shape=[3])])\n",
    "decoder = keras.models.Sequential([keras.layers.Dense(3, input_shape=[2])])\n",
    "autoencoder = keras.models.Sequential([encoder, decoder])\n",
    "\n",
    "autoencoder.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码与我们在前面章节中创建的所有 MLP 没有什么大不同。只有以下几点要注意：\n",
    "\n",
    "自编码器由两部分组成：编码器和解码器。两者都是常规的Sequential模型，每个含有一个紧密层，自编码器是一个编码器和解码器连起来的Sequential模型（模型可以用作其它模型中的层）。\n",
    "\n",
    "自编码器的输出等于输入。\n",
    "\n",
    "简单 PCA 不需要激活函数（即，所有神经元是线性的），且损失函数是 MSE。后面会看到更复杂的自编码器。\n",
    "\n",
    "现在用生成出来的 3D 数据集训练模型，并用模型编码数据集（即将其投影到 2D）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(X_train, X_train, epochs=20)\n",
    "codings = encoder.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，X_train既用来做输入，也用来做目标。图 17-2 显示了原始 3D 数据集（左侧）和自编码器隐藏层的输出（即编码层，右侧）。 可以看到，自编码器找到了投影数据的最佳二维平面，保留了数据的尽可能多的差异（就像 PCA 一样）。\n",
    "\n",
    "<img src='\n",
    "https://hands1ml.apachecn.org/img/e6301e8ec35adb6618df0c051f883dce.png\n",
    "'>\n",
    "<br>\n",
    "\n",
    "笔记：可以将自编码器当做某种形式的自监督学习（带有自动生成标签功能的监督学习，这个例子中标签等于输入）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 栈式自编码器\n",
    "就像我们讨论过的其他神经网络一样，自编码器可以有多个隐藏层。 在这种情况下，它们被称为栈式自编码器（或深度自编码器）。 添加更多层有助于自编码器了解更复杂的编码。 但是，必须注意不要让自编码器功能太强大。 设想一个编码器非常强大，只需学习将每个输入映射到一个任意数字（并且解码器学习反向映射）即可。 很明显，这样的自编码器将完美地重构训练数据，但它不会在过程中学习到任何有用的数据表征（并且它不可能很好地泛化到新的实例）。\n",
    "\n",
    "栈式自编码器的架构以中央隐藏层（编码层）为中心通常是对称的。 简单来说，它看起来像一个三明治。 例如，一个用于 MNIST 的自编码器（在第 3 章中介绍）可能有 784 个输入，其次是一个隐藏层，有 100 个神经元，然后是一个中央隐藏层，有 30 个神经元，然后是另一个隐藏层，有 100 个神经元，输出层有 784 个神经元。 这个栈式自编码器如图 17-3 所示。\n",
    "\n",
    "<img src='\n",
    "https://hands1ml.apachecn.org/img/2eb643c0821b45d0728233dbf25d1e46.png\n",
    "'>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用 Keras 实现栈式自编码器\n",
    "你可以像常规深度 MLP 一样实现栈式自编码器。 特别是，我们在第 11 章中用于训练深度网络的技术也可以应用。例如，下面的代码使用 SELU 激活函数为 Fashion MNIST 创建了一个栈式自编码器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(30, activation=\"selu\"),\n",
    "])\n",
    "stacked_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
    "stacked_ae.compile(loss=\"binary_crossentropy\",\n",
    "                   optimizer=keras.optimizers.SGD(lr=1.5))\n",
    "history = stacked_ae.fit(X_train, X_train, epochs=10,\n",
    "                         validation_data=[X_valid, X_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逐行看下这个代码：\n",
    "\n",
    "和之前一样，自编码器包括两个子模块：编码器和解码器。\n",
    "\n",
    "编码器接收28 × 28像素的灰度图片，打平为大小等于 784 的向量，用两个紧密层来处理，两个紧密层都是用 SELU 激活函数（还可以加上 LeCun 归一初始化，但因为网络不深，效果不大）。对于每张输入图片，编码器输出的向量大小是 30。\n",
    "\n",
    "解码器接收大小等于 30 的编码（编码器的输出），用两个紧密层来处理，最后的向量转换为28 × 28的数组，使解码器的输出和编码器的输入形状相同。\n",
    "\n",
    "编译时，使用二元交叉熵损失，而不是 MSE。将重建任务当做多标签分类问题：每个像素强度表示像素应该为黑色的概率。这么界定问题（而不是当做回归问题），可以使模型收敛更快。\n",
    "\n",
    "最后，使用X_train既作为输入，也作为目标，来训练模型（相似的，使用X_valid既作为验证的输入也作为目标）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 可视化重建\n",
    "确保自编码器训练得当的方式之一，是比较输入和输出：差异不应过大。画一些验证集的图片，及其重建："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def show_reconstructions(model, n_images=5):\n",
    "    reconstructions = model.predict(X_valid[:n_images])\n",
    "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
    "    for image_index in range(n_images):\n",
    "        plt.subplot(2, n_images, 1 + image_index)\n",
    "        plot_image(X_valid[image_index])\n",
    "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
    "        plot_image(reconstructions[image_index])\n",
    "\n",
    "show_reconstructions(stacked_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以认出重建，但图片有些失真。需要再训练模型一段时间，或使编码器和解码器更深，或使编码更大。但如果使网络太强大，就学不到数据中的规律。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 可视化 Fashion MNIST 数据集\n",
    "训练好栈式自编码器之后，就可以用它给数据集降维了。可视化的话，结果不像（第 8 章其它介绍的）其它降维方法那么好，但自编码器的优势是可以处理带有多个实例多个特征的大数据集。所以一个策略是利用自编码器将数据集降维到一个合理的水平，然后使用另外一个降维算法做可视化。用这个策略来可视化 Fashion MNIST。首先，使用栈式自编码器的编码器将维度降到 30，然后使用 Scikit-Learn 的 t-SNE 算法实现，将维度降到 2 并做可视化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X_valid_compressed = stacked_encoder.predict(X_valid)\n",
    "tsne = TSNE()\n",
    "X_valid_2D = tsne.fit_transform(X_valid_compressed)\n",
    "\n",
    "# 对数据集作图：\n",
    "plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap=\"tab10\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图 17-5 展示了结果的散点图（并展示了一些图片）。t-SNE 算法区分除了几类，比较符合图片的类别（每个类的颜色不一样）。\n",
    "\n",
    "<img src='\n",
    "https://hands1ml.apachecn.org/img/fc72779301071ddc44cc9423b21732bc.png\n",
    "'>\n",
    "<br>\n",
    "\n",
    "自编码器的另一个用途是无监督预训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用栈式自编码器做无监督预训练\n",
    "第 11 章讨论过，如果要处理一个复杂的监督任务，但又缺少标签数据，解决的方法之一，是找一个做相似任务的神经网络，复用它的底层。这么做就可以使用少量训练数据训练出高性能的模型，因为模型不必学习所有低层次特征；模型可以复用之前的特征探测器。\n",
    "\n",
    "相似的，如果有一个大数据集，但大部分实例是无标签的，可以用全部数据训练一个栈式自编码器，然后使用其底层创建一个神经网络，再用有标签数据来训练。例如，图 17-6 展示了如何使用栈式自编码器来做分类的无监督预训练。当训练分类器时，如果标签数据不足，可以冻住预训练层（底层）。\n",
    "\n",
    "<img src='\n",
    "https://hands1ml.apachecn.org/img/6a262b3ada6d315c0ff9d176785f0e0d.png\n",
    "'>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "笔记：无标签数据很多，有标签数据数据很少，非常普遍。搭建一个大无便签数据集很便宜（比如，一段小脚本可以从网上下载许多图片），但是给这些图片打标签（比如，将其标签为可爱或不可爱）只有人做才靠谱。打标签又耗时又耗钱，所以人工标注实例有几千就不错了。\n",
    "\n",
    "代码实现没有特殊之处：用所有训练数据训练自编码器，然后用编码器层创建新的神经网络（本章有练习题例子）。\n",
    "\n",
    "接下来，看看关联权重的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 关联权重\n",
    "当自编码器整齐地对称时，就像我们刚刚构建的那样，一种常用方法是将解码器层的权重与编码器层的权重相关联。 这样减半了模型中的权重数量，加快了训练速度，并限制了过度拟合的风险。具体来说，如果自编码器总共具有N个层（不算输入层），并且W[L]表示第L层的连接权重（例如，层 1 是第一隐藏层，则层N / 2是编码层，而层N是输出层），则解码器层权重可以简单地定义为：W[N–L+1] = W[L]^T（其中L = 1, 2, ..., N/2）。\n",
    "\n",
    "使用 Keras 将层的权重关联起来，先定义一个自定义层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseTranspose(keras.layers.Layer):\n",
    "    def __init__(self, dense, activation=None, **kwargs):\n",
    "        self.dense = dense\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        super().__init__(**kwargs)\n",
    "    def build(self, batch_input_shape):\n",
    "        self.biases = self.add_weight(name=\"bias\", initializer=\"zeros\",\n",
    "                                      shape=[self.dense.input_shape[-1]])\n",
    "        super().build(batch_input_shape)\n",
    "    def call(self, inputs):\n",
    "        z = tf.matmul(inputs, self.dense.weights[0], transpose_b=True)\n",
    "        return self.activation(z + self.biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义层的作用就像一个常规紧密层，但使用了另一个紧密层的权重，并且做了转置（设置transpose_b=True等同于转置第二个参数，但在matmul()运算中实时做转置更为高效）。但是，要使用自己的偏置向量。然后，创建一个新的栈式自编码器，将解码器的紧密层和编码器的紧密层关联起来："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_1 = keras.layers.Dense(100, activation=\"selu\")\n",
    "dense_2 = keras.layers.Dense(30, activation=\"selu\")\n",
    "\n",
    "tied_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    dense_1,\n",
    "    dense_2\n",
    "])\n",
    "\n",
    "tied_decoder = keras.models.Sequential([\n",
    "    DenseTranspose(dense_2, activation=\"selu\"),\n",
    "    DenseTranspose(dense_1, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "\n",
    "tied_ae = keras.models.Sequential([tied_encoder, tied_decoder])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个模型的重建误差小于前一个模型，且参数量只有一半。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一次训练一个自编码器\n",
    "不是一次完成整个栈式自编码器的训练，而是一次训练一个浅自编码器，然后将所有这些自编码器堆叠到一个栈式自编码器（因此名称）中，通常要快得多，如图 17-7 所示。 这个方法如今用的不多了，但偶尔还会撞见谈到“贪婪层级训练”的论文，所以还是看一看。\n",
    "\n",
    "<img src='\n",
    "https://hands1ml.apachecn.org/img/2e97115a3976ddb176e401dcfa95b53c.png\n",
    "'>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练的第一阶段，第一个自编码器学习重构输入。 然后，使用整个训练集训练第一个自编码器，得到一个新的（压缩过的）训练集。然后用这个数据集训练第二个自编码器。这是第二阶段的训练。最后，我们用所有这些自编码器创建一个三明治结构，见图 17-7（即，先把每个自编码器的隐藏层叠起来，再加上输出层）。这样就得到了最终的栈式自编码器（见笔记本）。我们可以用这种方式训练更多的自编码器，搭建非常深的栈式自编码器。\n",
    "\n",
    "正如前面讨论过的，现在的一大趋势是 Geoffrey Hinton 等人在 2006 年发现的，靠这种贪婪层级方法，可以用无监督方式训练神经网络。他们还使用了受限玻尔兹曼机（RBM，见附录 E）。但在 2007 年，Yoshua Bengio 发现只用自编码器也可以达到不错的效果。在这几年间，自编码器是唯一的有效训练深度网络的方法，知道出现第 11 章介绍过的方法。\n",
    "\n",
    "自编码器不限于紧密网络：还有卷积自编码器和循环自编码器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积自编码器\n",
    "如果处理的是图片，则前面介绍的自编码器的效果可能一般（除非图片非常小）。第 14 章介绍过，对于图片任务，卷积神经网络比紧密网络的效果更好。所以如果想用自编码器来处理图片的话（例如，无监督预训练或降维），你需要搭建一个卷积自编码器。编码器是一个包含卷积层和池化层的常规 CNN。通常降低输入的空间维度（即，高和宽），同时增加深度（即，特征映射的数量）。解码器的工作相反（放大图片，压缩深度），要这么做的话，可以转置卷积层（或者，可以将上采样层和卷积层合并）。下面是一个卷积自编码器处理 Fashion MNIST 的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "conv_encoder = keras.models.Sequential([\n",
    "    keras.layers.Reshape([28, 28, 1], input_shape=(28, 28)),\n",
    "    keras.layers.Conv2D(16, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    keras.layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
    "    keras.layers.MaxPool2D(pool_size=2)\n",
    "])\n",
    "\n",
    "conv_decoder = keras.models.Sequential([\n",
    "    keras.layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding=\"valid\", activation=\"selu\", input_shape=(3, 3, 64)),\n",
    "    keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding=\"same\", activation=\"selu\"),\n",
    "    keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, padding=\"same\", activation=\"selu\"),\n",
    "    keras.layers.Conv2DTranspose(1, kernel_size=3, strides=1, padding=\"same\", activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "\n",
    "conv_ae = keras.models.Sequential([conv_encoder, conv_decoder])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 循环自编码器\n",
    "如果你想用自编码器处理序列，比如对时间序列或文本无监督学习和降维，则循环神经网络要优于紧密网络。搭建循环自编码器很简单：编码器是一个序列到向量的 RNN，而解码器是向量到序列的 RNN："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrent_encoder = keras.models.Sequential([\n",
    "    keras.layers.LSTM(100, return_sequences=True, input_shape=[None, 28]),\n",
    "    keras.layers.LSTM(30)\n",
    "])\n",
    "recurrent_decoder = keras.models.Sequential([\n",
    "    keras.layers.RepeatVector(28, input_shape=[30]),\n",
    "    keras.layers.LSTM(100, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(28, activation=\"sigmoid\"))\n",
    "])\n",
    "recurrent_ae = keras.models.Sequential([recurrent_encoder, recurrent_decoder])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个循环自编码器可以处理任意长度的序列，每个时间步有 28 个维度。这意味着，可以将 Fashion MNIST 的图片作为几行序列来处理。注意，解码器第一层用的是RepeatVector，以保证在每个时间步将输入向量传给解码器。\n",
    "\n",
    "我们现在已经看过了多种自编码器（基本的、栈式的、卷积的、循环的），学习了训练的方法（一次性训练或逐层训练）。还学习了两种应用：视觉可视化和无监督学习。\n",
    "\n",
    "为了让自编码学习特征，我们限制了编码层的大小（使它处于不完整的状态）。还可以使用许多其他的限制方法，可以让编码层和输入层一样大，甚至更大，得到一个过完成的自编码器。下面就是其中一些方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 降噪自编码\n",
    "另一种强制自编码器学习特征的方法是为其输入添加噪声，对其进行训练以恢复原始的无噪声输入。 自 20 世纪 80 年代以来，使用自编码器消除噪音的想法已经出现（例如，在 Yann LeCun 的 1987 年硕士论文中提到过）。 在 2008 年的一篇论文中，帕斯卡尔文森特等人。 表明自编码器也可用于特征提取。 在 2010 年的一篇炉温中， Vincent 等人引入了栈式降噪自编码器。\n",
    "\n",
    "噪声可以是添加到输入的纯高斯噪声，或者可以随机关闭输入，就像丢弃（在第 11 章介绍）。 图 17-8 显示了这两种方法。\n",
    "\n",
    "<img src='\n",
    "https://hands1ml.apachecn.org/img/34a85484de696688796d6e35f8e7a0a3.png\n",
    "'>\n",
    "<br>\n",
    "图 17-8：自编码器可以用于特征提取，通过添加噪声或随机丢弃输入来训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现很简单：常规的栈式自编码器中有一个应用于输入的Dropout层（或使用GaussianNoise层）。Dropout层只在训练中起作用（GaussianNoise层也只在训练中起作用）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(30, activation=\"selu\")\n",
    "])\n",
    "dropout_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "dropout_ae = keras.models.Sequential([dropout_encoder, dropout_decoder])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图 17-9 展示了一些带有造影的图片（有一半像素被丢弃），重建图片是用基于丢弃的自编码器实现的。注意自编码器是如何猜测图片中不存在的细节的，比如四张图片的领口。\n",
    "\n",
    "<img src='\n",
    "https://hands1ml.apachecn.org/img/d726c67a612e5268f2123baf0d028222.png\n",
    "'>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 稀疏自编码器\n",
    "通常良好特征提取的另一种约束是稀疏性：通过向损失函数添加适当的项，让自编码器减少编码层中活动神经元的数量。 例如，可以让编码层中平均只有 5% 的活跃神经元。 这迫使自编码器将每个输入表示为少量激活的组合。 因此，编码层中的每个神经元通常都会代表一个有用的特征（如果每个月只能说几个字，你会说的特别精炼）。\n",
    "\n",
    "使用 sigmoid 激活函数可以实现这个目的。添加一个编码层（比如，有 300 个神经元），给编码层的激活函数添加ℓ1正则（解码器就是一个常规解码器）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_l1_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(300, activation=\"sigmoid\"),\n",
    "    keras.layers.ActivityRegularization(l1=1e-3)\n",
    "])\n",
    "sparse_l1_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[300]),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "sparse_l1_ae = keras.models.Sequential([sparse_l1_encoder, sparse_l1_decoder])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ActivityRegularization只是返回输入，但副作用是新增了训练损失，大小等于输入的绝对值之和（这个层只在训练中起作用）。等价的，可以移出ActivityRegularization，并在前一层设置activity_regularizer=keras.regularizers.l1(1e-3)。这项惩罚可以让神经网络产生接近 0 的编码，如果没有正确重建输入，还是会有损失，仍然会产生一些非 0 值。不使用ℓ2，而使用ℓ1，可以让神经网络保存最重要的编码，同时消除输入图片不需要的编码（而不是压缩所有编码）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一种结果更好的方法是在每次训练迭代中测量编码层的实际稀疏度，当偏移目标值，就惩罚模型。 我们通过计算整个训练批次中编码层中每个神经元的平均激活来实现。 批量大小不能太小，否则平均数不准确。\n",
    "\n",
    "一旦我们对每个神经元进行平均激活，我们希望通过向损失函数添加稀疏损失来惩罚太活跃的神经元，或不够活跃的神经元。 例如，如果我们测量一个神经元的平均激活值为 0.3，但目标稀疏度为 0.1，那么它必须受到惩罚才能激活更少。 一种方法可以简单地将平方误差(0.3-0.1)^2添加到损失函数中，但实际上更好的方法是使用 Kullback-Leibler 散度（在第 4 章中简要讨论），它具有比均方误差更强的梯度，如图 17-10 所示。\n",
    "\n",
    "<img src='\n",
    "https://hands1ml.apachecn.org/img/3dfe7472d69611d43ccd638d7eb71169.png\n",
    "'>\n",
    "<br>\n",
    "图 17-10：Kullback-Leibler 散度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定两个离散的概率分布P和Q，这些分布之间的 KL 散度，记为D[KL](P || Q)，可以使用公式 17-1 计算。\n",
    "<img src='\n",
    "https://hands1ml.apachecn.org/img/84f8b1f35d7af4b1e2321b25be6f00d9.png\n",
    "'>\n",
    "<br>\n",
    "在我们的例子中，我们想要测量编码层中的神经元将激活的目标概率p与实际概率q（即，训练批次上的平均激活）之间的差异。 所以 KL 散度简化为公式 17-2。\n",
    "\n",
    "<img src='\n",
    "https://hands1ml.apachecn.org/img/96a7a903ca020a64ae2a2e839ff98ac1.png\n",
    "'>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一旦我们已经计算了编码层中每个神经元的稀疏损失，就相加这些损失，并将结果添加到损失函数中。 为了控制稀疏损失和重构损失的相对重要性，我们可以用稀疏权重超参数乘以稀疏损失。 如果这个权重太高，模型会紧贴目标稀疏度，但它可能无法正确重建输入，导致模型无用。 相反，如果它太低，模型将大多忽略稀疏目标，它不会学习任何有趣的功能。\n",
    "\n",
    "现在就可以实现基于 KL 散度的稀疏自编码器了。首先，创建一个自定义正则器来实现 KL 散度正则："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "kl_divergence = keras.losses.kullback_leibler_divergence\n",
    "\n",
    "class KLDivergenceRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, weight, target=0.1):\n",
    "        self.weight = weight\n",
    "        self.target = target\n",
    "    def __call__(self, inputs):\n",
    "        mean_activities = K.mean(inputs, axis=0)\n",
    "        return self.weight * (\n",
    "            kl_divergence(self.target, mean_activities) +\n",
    "            kl_divergence(1 - self.target, 1 - mean_activities)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用KLDivergenceRegularizer作为编码层的激活函数，创建稀疏自编码器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kld_reg = KLDivergenceRegularizer(weight=0.05, target=0.1)\n",
    "sparse_kl_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(300, activation=\"sigmoid\", activity_regularizer=kld_reg)\n",
    "])\n",
    "sparse_kl_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[300]),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "sparse_kl_ae = keras.models.Sequential([sparse_kl_encoder, sparse_kl_decoder])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 Fashion MNIST 上训练好稀疏自编码器之后，编码层中的神经元的激活大部分接近 0（70% 的激活小于 0.1），所有神经元的平均值在 0.1 附近（90% 的平均激活在 0.1 和 0.2 之间）见图 17-11。\n",
    "\n",
    "<img src='\n",
    "https://hands1ml.apachecn.org/img/2de4723c6249ec91b3cb15bc31d64b7f.png\n",
    "'>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 变分自编码器（VAE）\n",
    "Diederik Kingma 和 Max Welling 于 2013 年推出了另一类重要的自编码器，并迅速成为最受欢迎的自编码器类型之一：变分自编码器。\n",
    "\n",
    "它与我们迄今为止讨论的所有自编码器非常不同，特别是：\n",
    "\n",
    "它们是概率自编码器，意味着即使在训练之后，它们的输出部分也是偶然确定的（相对于仅在训练过程中使用随机性的自编码器的去噪）。\n",
    "\n",
    "最重要的是，它们是生成自编码器，这意味着它们可以生成看起来像从训练集中采样的新实例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这两个属性使它们与 RBM 非常相似（见附录 E），但它们更容易训练，并且取样过程更快（在 RBM 之前，您需要等待网络稳定在“热平衡”之后才能进行取样一个新的实例）。正如其名字，变分自编码器要做变分贝叶斯推断（第 9 章介绍过），这是估计变微分推断的一种有效方式。\n",
    "\n",
    "我们来看看他们是如何工作的。 图 17-12（左）显示了一个变分自编码器。 当然，您可以认识到所有自编码器的基本结构，编码器后跟解码器（在本例中，它们都有两个隐藏层），但有一个转折点：不是直接为给定的输入生成编码 ，编码器产生平均编码μ和标准差σ。 然后从平均值μ和标准差σ的高斯分布随机采样实际编码。 之后，解码器正常解码采样的编码。 该图的右侧部分显示了一个训练实例通过此自编码器。 首先，编码器产生μ和σ，随后对编码进行随机采样（注意它不是完全位于μ处），最后对编码进行解码，最终的输出与训练实例类似。\n",
    "\n",
    "<img src='\n",
    "https://hands1ml.apachecn.org/img/7c9060e3ee9cbc624bfadb3ac589452a.png\n",
    "'>\n",
    "<br>\n",
    "图 17-12: 变分自编码器。 左：变分自编码器结构。 右：一个训练实例通过变分自编码器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从图中可以看出，尽管输入可能具有非常复杂的分布，但变分自编码器倾向于产生编码，看起来好像它们是从简单的高斯分布采样的：在训练期间，损失函数（将在下面讨论）推动 编码在编码空间（也称为潜在空间）内逐渐迁移以占据看起来像高斯点集成的云的大致（超）球形区域。 一个重要的结果是，在训练了一个变分自编码器之后，你可以很容易地生成一个新的实例：只需从高斯分布中抽取一个随机编码，对它进行解码就可以了！\n",
    "\n",
    "再来看看损失函数。 它由两部分组成。 首先是通常的重建损失，推动自编码器重现其输入（我们可以使用交叉熵来解决这个问题，如前所述）。 第二种是潜在的损失，推动自编码器使编码看起来像是从简单的高斯分布中采样，为此我们使用目标分布（高斯分布）与编码实际分布之间的 KL 散度。 数学比以前复杂一点，特别是因为高斯噪声，它限制了可以传输到编码层的信息量（从而推动自编码器学习有用的特征）。 幸好，这些方程经过简化，可以用公式 17-3 计算潜在损失：\n",
    "\n",
    "<img src='\n",
    "https://hands1ml.apachecn.org/img/9273964ee58f08a1c76543fe9af21c40.png\n",
    "'>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
